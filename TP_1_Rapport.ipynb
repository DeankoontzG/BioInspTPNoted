{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b20aca7-43da-4e06-8a6f-f1ca5de6c104",
   "metadata": {},
   "source": [
    "# Rapport sur TP - Artus et Guilhem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd918d-a3d7-4e59-8e93-b703db09ddfb",
   "metadata": {},
   "source": [
    "## Partie 1 : copie du rapport intégré au code \n",
    "\n",
    "- Data train = taille images * nb images = 28 * 28 * nb images\n",
    "- Label train = taille finale du vecteur * nb images  = 10 * nb images\n",
    "- Logique similaire pour données de test\n",
    "- Taille entrée = taille de w = data_train nb de colonnes * label_train*nombre de colonnes = 784 * 10\n",
    "- Taille sortie = taille de b = 1 * label_train nb de colonnes = 1 * 10\n",
    "- Taille de x = taille images * 5\n",
    "- Taille de y = taille de 5 résultats = 5 * 10\n",
    "- Taille de t = comme y\n",
    "- Taille of grad = 5 * 10. Intuitivement celui-ci je ne l'ai pas, commment ce nb va-t-il augmenter quand nous allons appliquer la chain rule ?\n",
    "- \n",
    "\n",
    "### Ce que donne le code : \n",
    "Taille entrée = 784, taille sortie = 10\n",
    " size of data_train : torch.Size([63000, 784])\n",
    " size of label_train : torch.Size([63000, 10])\n",
    " size of data_test : torch.Size([7000, 784])\n",
    " size of label_test : torch.Size([7000, 10])\n",
    " size of w : torch.Size([784, 10])\n",
    " size of b : torch.Size([1, 10])\n",
    " size of x : torch.Size([5, 784])\n",
    " size of y : torch.Size([5, 10])\n",
    " size of grad : torch.Size([5, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917181fa-f242-49e2-854f-0b0ec1c01d9b",
   "metadata": {},
   "source": [
    "## Partie 2 : Shallow Network - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c28bb1-3bea-49be-8508-ed7b3f6bae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa9ed2a9-2101-463f-8d32-d19deefb7457",
   "metadata": {},
   "source": [
    "## Partie 4 : CNN \n",
    "\n",
    "### Choix du modèle\n",
    "Conformément à l'ennoncé du TP, nous avons choisi d'implémenter un CNN en appliquant l'architecture LeNet. Notre travail a consisté à l'adpater à la taille de nos images, en prenant en compte les bonnes dimension. Pas besoin de padding dans notre cas car déjà inclu dans les données de base apparemment.\n",
    "\n",
    "#### Choix des couches et dimensions associées : \n",
    "- Convolution 1 (+relu) : entrée en dimension 1*28*28 (car niveaux de gris uniquement donc pas *3 comme en couleur), sortie en 24*24*6 après convolution (kernel_size = 5, stride =1)\n",
    "- Pooling 1 (+relu) : prends les données de Conv1 en entrée, sortie en 12*12*6 (kernel_size=2, stride=2)\n",
    "- Convolution 2 (+ relu) : entrée de taille précédente, sortie en 8*8*16 (kernel_size=5, stride=1)\n",
    "- Pooling 2 (+ relu) : entrée de taille précédente, sortie en 4*4*16 (kernel_size=2, stride=2)\n",
    "- Fully connected 1 (Linear layer) : input: 16 * 4 * 4, output: 120 \n",
    "- Fully connected 2 (Linear layer) : input: 120, output: 84 \n",
    "- Output layer (Fully connected) ; input: 84, output: 10\n",
    "\n",
    "Nous avons choisi une structure qui passe progressivement de 120 à 10 dimensions, car après test c'est ce qui semblait le mieux fonctionner.\n",
    "\n",
    "## Hyperparamètres\n",
    "\n",
    "Basé sur un grid-search, nous avons choisi : \n",
    "- Taille de batch : 64 (pour gagner en efficacité, batch size plus réduit n'apportait que peu à la qualité du modèle).\n",
    "- Nombre d'époques : 30 (même si stabilisation à partir de 15 epochs, même si solution optimale trouvée autour de 25 on pourrait justifier qu'au delà de 15 notre modèle commence à over-fiter)\n",
    "- Taux d’apprentissage : 0.005\n",
    "\n",
    "## Résultats d'entraînement\n",
    "\n",
    "L’évaluation de la précision sur l’ensemble test montre :  \n",
    "- Une progression rapide durant les premières epochs, avec une précision passant de ~36% à plus de 90% en 4 epochs.  \n",
    "- À partir de la 10e époque, la précision dépasse 95%.  \n",
    "- Après environ 15 epochs, la précision atteint un premier plateau aux alentours de 97-98%, première convergence du modèle.  \n",
    "- Au delà, les performances oscillent autour de la convergence avec semble-t-il une légère tendance à l'amélioration. Et ce sans sur-apprentissage marqué. Plus de puissance de calcul nous permettrait de vérifier si la performance continue vraiment à s'améliorer ou stagne au delà, mais pas besoin d'aller au delà de 15 epochs pour notre modèle.\n",
    "\n",
    "| Epoch | Précision test |\n",
    "|-------|----------------|\n",
    "| 1     | 36%            |\n",
    "| 4     | 91%            |\n",
    "| 10    | 95%            |\n",
    "| 15    | 97.6%          |\n",
    "| 25    | 98.2%          |\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Le CNN utilisé permet d’obtenir une précision satisfaisante (>97%) sur MNIST, qui est certes un jeu de données réputé simple. Donc une architecture simple, sans trop besoin d'optimisation d'hyper paramètres suffit amplement.\n",
    "\n",
    "L’entraînement est considéré comme terminé vers 15 epochs, où la précision se stabilise, ce qui permettrait d’économiser du temps de calcul sans perte significative de performance.  \n",
    "\n",
    "A remarquer cependant que notre CNN n'offre pas d'augmentation significative de performances, par rapport aux modèles explorés plus tôt. Il faudrait donc sur ces données privilégier des méthodes plus simples et moins coûteuses en en énergie. Ce n'est pas si surprenant car les données MNIST sont réputées comme \"simples\", utiliser un CNN complèxe semble donc overkill sur un tel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b38156-384f-4a05-b3bc-4b610a635e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
