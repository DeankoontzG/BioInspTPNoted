{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce45af9-0995-4914-b5ea-06f185cba084",
   "metadata": {},
   "source": [
    "# Réponses aux questions du TP :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed72c1b-3c83-4f3d-a8ae-8670f84c9f38",
   "metadata": {},
   "source": [
    "Equipe : Artus Bleton & Guilhem Dupuy\n",
    "\n",
    "Répartition du travail : gloablement travail réalisé ensemble et en échangeant, Deep Network code par Artus, CNN code par Guilhem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e4656-fba2-48df-8b19-997020e235d5",
   "metadata": {},
   "source": [
    "## 5 Part 1 : Perceptron\n",
    "- Data train = taille images * nb images = 28 * 28 * nb images\n",
    "- Label train = taille finale du vecteur * nb images  = 10 * nb images\n",
    "- Logique similaire pour données de test\n",
    "- Taille entrée = taille de w = data_train nb de colonnes * label_train*nombre de colonnes = 784 * 10\n",
    "- Taille sortie = taille de b = 1 * label_train nb de colonnes = 1 * 10\n",
    "- Taille de x = taille images * 5\n",
    "- Taille de y = taille de 5 résultats = 5 * 10\n",
    "- Taille de t = comme y\n",
    "- Taille of grad = 5 * 10. Intuitivement celui-ci je ne l'ai pas, commment ce nb va-t-il augmenter quand nous allons appliquer la chain rule ?\n",
    "- \n",
    "\n",
    "### Ce que donne le code : \n",
    "Taille entrée = 784, taille sortie = 10\n",
    " size of data_train : torch.Size([63000, 784])\n",
    " size of label_train : torch.Size([63000, 10])\n",
    " size of data_test : torch.Size([7000, 784])\n",
    " size of label_test : torch.Size([7000, 10])\n",
    " size of w : torch.Size([784, 10])\n",
    " size of b : torch.Size([1, 10])\n",
    " size of x : torch.Size([5, 784])\n",
    " size of y : torch.Size([5, 10])\n",
    " size of grad : torch.Size([5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4591b025-b690-4279-8751-087e1ea10ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille entrée = 784, taille sortie = 10\n",
      " size of data_train : torch.Size([63000, 784])\n",
      " size of label_train : torch.Size([63000, 10])\n",
      " size of data_test : torch.Size([7000, 784])\n",
      " size of label_test : torch.Size([7000, 10])\n",
      " size of w : torch.Size([784, 10])\n",
      " size of b : torch.Size([1, 10])\n",
      "tensor([0.8084])\n",
      " size of x : torch.Size([5, 784])\n",
      " size of y : torch.Size([5, 10])\n",
      " size of grad : torch.Size([5, 10])\n",
      "tensor([0.8256])\n",
      "tensor([0.8351])\n",
      "tensor([0.8384])\n",
      "tensor([0.8437])\n",
      "tensor([0.8476])\n",
      "tensor([0.8509])\n",
      "tensor([0.8523])\n",
      "tensor([0.8531])\n",
      "tensor([0.8526])\n"
     ]
    }
   ],
   "source": [
    "# perceptron_pytorch\n",
    "\n",
    "import gzip, numpy, torch\n",
    "    \n",
    "batch_size = 5 # nombre de données lues à chaque fois\n",
    "nb_epochs = 10 # nombre de fois que la base de données sera lue\n",
    "eta = 0.00001 # taux d'apprentissage\n",
    "\n",
    "# on lit les données\n",
    "((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('mnist_TP1.pkl.gz'))\n",
    "\n",
    "# on initialise le modèle et ses poids\n",
    "w = torch.empty((data_train.shape[1],label_train.shape[1]),dtype=torch.float)\n",
    "print(f\"Taille entrée = {data_train.shape[1]}, taille sortie = {label_train.shape[1]}\")\n",
    "b = torch.empty((1,label_train.shape[1]),dtype=torch.float)\n",
    "torch.nn.init.uniform_(w,-0.001,0.001)\n",
    "torch.nn.init.uniform_(b,-0.001,0.001)\n",
    "\n",
    "#Affichage des tailles\n",
    "print(f\" size of data_train : {data_train.shape}\")\n",
    "print(f\" size of label_train : {label_train.shape}\")\n",
    "print(f\" size of data_test : {data_test.shape}\")\n",
    "print(f\" size of label_test : {label_test.shape}\")\n",
    "print(f\" size of w : {w.shape}\")\n",
    "print(f\" size of b : {b.shape}\")\n",
    "\n",
    "nb_data_train = data_train.shape[0]\n",
    "nb_data_test = data_test.shape[0]\n",
    "indices = numpy.arange(nb_data_train)\n",
    "\n",
    "for n in range(nb_epochs):\n",
    "    # on mélange les (indices des) données\n",
    "    numpy.random.shuffle(indices)\n",
    "    # on lit toutes les (indices des) données d'apprentissage\n",
    "    for i in range(0,nb_data_train,batch_size):\n",
    "        # on récupère les entrées\n",
    "        x = data_train[indices[i:i+batch_size]]\n",
    "        # on calcule la sortie du modèle\n",
    "        y = torch.mm(x,w)+b\n",
    "        # on regarde les vrais labels\n",
    "        t = label_train[indices[i:i+batch_size]]\n",
    "        # on met à jour les poids\n",
    "        grad = (t-y)      #La fonction d'activation est donc linéaire je crois, avec une loss fonction de type somme des carrés ?\n",
    "        w += eta * torch.mm(x.T,grad)\n",
    "        b += eta * grad.sum(axis=0)\n",
    "\n",
    "        if i == 0 and n == 1 : \n",
    "            print(f\" size of x : {x.shape}\")\n",
    "            print(f\" size of y : {y.shape}\")\n",
    "            print(f\" size of grad : {grad.shape}\")\n",
    "\n",
    "    # test du modèle (on évalue la progression pendant l'apprentissage)\n",
    "    acc = 0.\n",
    "    # on lit toutes les donnéees de test\n",
    "    for i in range(nb_data_test):\n",
    "        # on récupère l'entrée\n",
    "        x = data_test[i:i+1]\n",
    "        # on calcule la sortie du modèle\n",
    "        y = torch.mm(x,w)+b\n",
    "        # on regarde le vrai label\n",
    "        t = label_test[i:i+1]\n",
    "        # on regarde si la sortie est correcte\n",
    "        acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "    # on affiche le pourcentage de bonnes réponses\n",
    "    print(acc/nb_data_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ad303-bbe8-4786-8f31-76db39035165",
   "metadata": {},
   "source": [
    "# 6 Part 2 : Shallow Network - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8e1222-f994-4d0f-8333-9861796b9965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63000, 784) (63000,)\n",
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8606\u001b[0m       \u001b[32m0.8695\u001b[0m        \u001b[35m0.4523\u001b[0m  2.0200\n",
      "      2        \u001b[36m0.3825\u001b[0m       \u001b[32m0.8924\u001b[0m        \u001b[35m0.3623\u001b[0m  1.8158\n",
      "      3        \u001b[36m0.3225\u001b[0m       \u001b[32m0.9025\u001b[0m        \u001b[35m0.3249\u001b[0m  1.8368\n",
      "      4        \u001b[36m0.2886\u001b[0m       \u001b[32m0.9098\u001b[0m        \u001b[35m0.3000\u001b[0m  1.8663\n",
      "      5        \u001b[36m0.2630\u001b[0m       \u001b[32m0.9154\u001b[0m        \u001b[35m0.2803\u001b[0m  1.9904\n",
      "      6        \u001b[36m0.2418\u001b[0m       \u001b[32m0.9210\u001b[0m        \u001b[35m0.2635\u001b[0m  1.9226\n",
      "      7        \u001b[36m0.2236\u001b[0m       \u001b[32m0.9260\u001b[0m        \u001b[35m0.2489\u001b[0m  1.8645\n",
      "      8        \u001b[36m0.2076\u001b[0m       \u001b[32m0.9289\u001b[0m        \u001b[35m0.2360\u001b[0m  1.9185\n",
      "      9        \u001b[36m0.1934\u001b[0m       \u001b[32m0.9329\u001b[0m        \u001b[35m0.2246\u001b[0m  2.1750\n",
      "     10        \u001b[36m0.1807\u001b[0m       \u001b[32m0.9363\u001b[0m        \u001b[35m0.2144\u001b[0m  2.2650\n",
      "     11        \u001b[36m0.1693\u001b[0m       \u001b[32m0.9394\u001b[0m        \u001b[35m0.2053\u001b[0m  2.5278\n",
      "     12        \u001b[36m0.1590\u001b[0m       \u001b[32m0.9410\u001b[0m        \u001b[35m0.1971\u001b[0m  2.3767\n",
      "     13        \u001b[36m0.1495\u001b[0m       \u001b[32m0.9432\u001b[0m        \u001b[35m0.1895\u001b[0m  2.5524\n",
      "     14        \u001b[36m0.1410\u001b[0m       \u001b[32m0.9449\u001b[0m        \u001b[35m0.1827\u001b[0m  2.5751\n",
      "     15        \u001b[36m0.1331\u001b[0m       \u001b[32m0.9451\u001b[0m        \u001b[35m0.1765\u001b[0m  2.4796\n",
      "     16        \u001b[36m0.1258\u001b[0m       \u001b[32m0.9459\u001b[0m        \u001b[35m0.1709\u001b[0m  2.4532\n",
      "     17        \u001b[36m0.1192\u001b[0m       \u001b[32m0.9475\u001b[0m        \u001b[35m0.1658\u001b[0m  2.4240\n",
      "     18        \u001b[36m0.1131\u001b[0m       \u001b[32m0.9494\u001b[0m        \u001b[35m0.1612\u001b[0m  2.4625\n",
      "     19        \u001b[36m0.1074\u001b[0m       \u001b[32m0.9510\u001b[0m        \u001b[35m0.1569\u001b[0m  2.2778\n",
      "     20        \u001b[36m0.1021\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.1530\u001b[0m  2.4803\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8571\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.5021\u001b[0m  2.3614\n",
      "      2        \u001b[36m0.3757\u001b[0m       \u001b[32m0.8838\u001b[0m        \u001b[35m0.3926\u001b[0m  2.4395\n",
      "      3        \u001b[36m0.3160\u001b[0m       \u001b[32m0.8967\u001b[0m        \u001b[35m0.3484\u001b[0m  2.1976\n",
      "      4        \u001b[36m0.2831\u001b[0m       \u001b[32m0.9087\u001b[0m        \u001b[35m0.3190\u001b[0m  2.4184\n",
      "      5        \u001b[36m0.2588\u001b[0m       \u001b[32m0.9163\u001b[0m        \u001b[35m0.2960\u001b[0m  2.3674\n",
      "      6        \u001b[36m0.2389\u001b[0m       \u001b[32m0.9213\u001b[0m        \u001b[35m0.2764\u001b[0m  2.2247\n",
      "      7        \u001b[36m0.2217\u001b[0m       \u001b[32m0.9263\u001b[0m        \u001b[35m0.2595\u001b[0m  2.1996\n",
      "      8        \u001b[36m0.2066\u001b[0m       \u001b[32m0.9294\u001b[0m        \u001b[35m0.2448\u001b[0m  2.2810\n",
      "      9        \u001b[36m0.1932\u001b[0m       \u001b[32m0.9317\u001b[0m        \u001b[35m0.2319\u001b[0m  2.4205\n",
      "     10        \u001b[36m0.1812\u001b[0m       \u001b[32m0.9359\u001b[0m        \u001b[35m0.2205\u001b[0m  2.4158\n",
      "     11        \u001b[36m0.1703\u001b[0m       \u001b[32m0.9383\u001b[0m        \u001b[35m0.2104\u001b[0m  2.1513\n",
      "     12        \u001b[36m0.1604\u001b[0m       \u001b[32m0.9414\u001b[0m        \u001b[35m0.2015\u001b[0m  2.1038\n",
      "     13        \u001b[36m0.1515\u001b[0m       \u001b[32m0.9443\u001b[0m        \u001b[35m0.1934\u001b[0m  2.1442\n",
      "     14        \u001b[36m0.1432\u001b[0m       \u001b[32m0.9462\u001b[0m        \u001b[35m0.1862\u001b[0m  2.1347\n",
      "     15        \u001b[36m0.1357\u001b[0m       \u001b[32m0.9478\u001b[0m        \u001b[35m0.1797\u001b[0m  2.2153\n",
      "     16        \u001b[36m0.1287\u001b[0m       \u001b[32m0.9490\u001b[0m        \u001b[35m0.1738\u001b[0m  2.4234\n",
      "     17        \u001b[36m0.1222\u001b[0m       \u001b[32m0.9498\u001b[0m        \u001b[35m0.1684\u001b[0m  2.4357\n",
      "     18        \u001b[36m0.1162\u001b[0m       \u001b[32m0.9505\u001b[0m        \u001b[35m0.1634\u001b[0m  2.4314\n",
      "     19        \u001b[36m0.1106\u001b[0m       \u001b[32m0.9522\u001b[0m        \u001b[35m0.1589\u001b[0m  2.4315\n",
      "     20        \u001b[36m0.1054\u001b[0m       \u001b[32m0.9532\u001b[0m        \u001b[35m0.1547\u001b[0m  2.3645\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0242\u001b[0m       \u001b[32m0.8594\u001b[0m        \u001b[35m0.4985\u001b[0m  1.2638\n",
      "      2        \u001b[36m0.4139\u001b[0m       \u001b[32m0.8859\u001b[0m        \u001b[35m0.3899\u001b[0m  1.2357\n",
      "      3        \u001b[36m0.3489\u001b[0m       \u001b[32m0.8941\u001b[0m        \u001b[35m0.3557\u001b[0m  1.1969\n",
      "      4        \u001b[36m0.3197\u001b[0m       \u001b[32m0.9002\u001b[0m        \u001b[35m0.3372\u001b[0m  1.2646\n",
      "      5        \u001b[36m0.3007\u001b[0m       \u001b[32m0.9022\u001b[0m        \u001b[35m0.3242\u001b[0m  1.2690\n",
      "      6        \u001b[36m0.2860\u001b[0m       \u001b[32m0.9046\u001b[0m        \u001b[35m0.3143\u001b[0m  1.2159\n",
      "      7        \u001b[36m0.2739\u001b[0m       \u001b[32m0.9079\u001b[0m        \u001b[35m0.3058\u001b[0m  1.3779\n",
      "      8        \u001b[36m0.2633\u001b[0m       \u001b[32m0.9102\u001b[0m        \u001b[35m0.2978\u001b[0m  1.3247\n",
      "      9        \u001b[36m0.2536\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m0.2904\u001b[0m  1.1924\n",
      "     10        \u001b[36m0.2449\u001b[0m       \u001b[32m0.9156\u001b[0m        \u001b[35m0.2836\u001b[0m  1.3222\n",
      "     11        \u001b[36m0.2368\u001b[0m       \u001b[32m0.9173\u001b[0m        \u001b[35m0.2774\u001b[0m  1.2078\n",
      "     12        \u001b[36m0.2293\u001b[0m       \u001b[32m0.9190\u001b[0m        \u001b[35m0.2715\u001b[0m  1.1958\n",
      "     13        \u001b[36m0.2225\u001b[0m       \u001b[32m0.9210\u001b[0m        \u001b[35m0.2659\u001b[0m  1.2106\n",
      "     14        \u001b[36m0.2161\u001b[0m       \u001b[32m0.9216\u001b[0m        \u001b[35m0.2612\u001b[0m  1.2540\n",
      "     15        \u001b[36m0.2103\u001b[0m       \u001b[32m0.9217\u001b[0m        \u001b[35m0.2569\u001b[0m  1.1926\n",
      "     16        \u001b[36m0.2048\u001b[0m       \u001b[32m0.9229\u001b[0m        \u001b[35m0.2531\u001b[0m  1.2101\n",
      "     17        \u001b[36m0.1997\u001b[0m       0.9225        \u001b[35m0.2494\u001b[0m  1.2068\n",
      "     18        \u001b[36m0.1948\u001b[0m       \u001b[32m0.9240\u001b[0m        \u001b[35m0.2462\u001b[0m  1.1991\n",
      "     19        \u001b[36m0.1902\u001b[0m       \u001b[32m0.9251\u001b[0m        \u001b[35m0.2432\u001b[0m  1.1911\n",
      "     20        \u001b[36m0.1858\u001b[0m       \u001b[32m0.9265\u001b[0m        \u001b[35m0.2402\u001b[0m  1.1932\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0842\u001b[0m       \u001b[32m0.8171\u001b[0m        \u001b[35m0.5941\u001b[0m  1.1783\n",
      "      2        \u001b[36m0.4232\u001b[0m       \u001b[32m0.8714\u001b[0m        \u001b[35m0.4378\u001b[0m  1.2145\n",
      "      3        \u001b[36m0.3492\u001b[0m       \u001b[32m0.8843\u001b[0m        \u001b[35m0.3924\u001b[0m  1.1970\n",
      "      4        \u001b[36m0.3174\u001b[0m       \u001b[32m0.8908\u001b[0m        \u001b[35m0.3678\u001b[0m  1.2806\n",
      "      5        \u001b[36m0.2968\u001b[0m       \u001b[32m0.8971\u001b[0m        \u001b[35m0.3500\u001b[0m  1.2873\n",
      "      6        \u001b[36m0.2811\u001b[0m       \u001b[32m0.9010\u001b[0m        \u001b[35m0.3365\u001b[0m  1.2647\n",
      "      7        \u001b[36m0.2681\u001b[0m       \u001b[32m0.9060\u001b[0m        \u001b[35m0.3250\u001b[0m  1.2342\n",
      "      8        \u001b[36m0.2573\u001b[0m       \u001b[32m0.9084\u001b[0m        \u001b[35m0.3151\u001b[0m  1.2349\n",
      "      9        \u001b[36m0.2480\u001b[0m       \u001b[32m0.9116\u001b[0m        \u001b[35m0.3068\u001b[0m  1.2267\n",
      "     10        \u001b[36m0.2397\u001b[0m       \u001b[32m0.9138\u001b[0m        \u001b[35m0.2994\u001b[0m  1.2313\n",
      "     11        \u001b[36m0.2324\u001b[0m       \u001b[32m0.9151\u001b[0m        \u001b[35m0.2931\u001b[0m  1.2213\n",
      "     12        \u001b[36m0.2258\u001b[0m       \u001b[32m0.9170\u001b[0m        \u001b[35m0.2869\u001b[0m  1.2026\n",
      "     13        \u001b[36m0.2197\u001b[0m       \u001b[32m0.9183\u001b[0m        \u001b[35m0.2819\u001b[0m  1.2030\n",
      "     14        \u001b[36m0.2140\u001b[0m       \u001b[32m0.9195\u001b[0m        \u001b[35m0.2762\u001b[0m  1.1739\n",
      "     15        \u001b[36m0.2085\u001b[0m       \u001b[32m0.9210\u001b[0m        \u001b[35m0.2714\u001b[0m  1.2392\n",
      "     16        \u001b[36m0.2035\u001b[0m       \u001b[32m0.9229\u001b[0m        \u001b[35m0.2673\u001b[0m  1.1957\n",
      "     17        \u001b[36m0.1988\u001b[0m       \u001b[32m0.9240\u001b[0m        \u001b[35m0.2641\u001b[0m  1.1892\n",
      "     18        \u001b[36m0.1942\u001b[0m       \u001b[32m0.9243\u001b[0m        \u001b[35m0.2609\u001b[0m  1.1920\n",
      "     19        \u001b[36m0.1900\u001b[0m       \u001b[32m0.9249\u001b[0m        \u001b[35m0.2578\u001b[0m  1.1734\n",
      "     20        \u001b[36m0.1860\u001b[0m       \u001b[32m0.9259\u001b[0m        \u001b[35m0.2547\u001b[0m  1.1890\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.2751\u001b[0m       \u001b[32m0.2297\u001b[0m        \u001b[35m2.2523\u001b[0m  1.9838\n",
      "      2        \u001b[36m2.2271\u001b[0m       \u001b[32m0.3698\u001b[0m        \u001b[35m2.2048\u001b[0m  2.0543\n",
      "      3        \u001b[36m2.1796\u001b[0m       \u001b[32m0.5037\u001b[0m        \u001b[35m2.1573\u001b[0m  2.2008\n",
      "      4        \u001b[36m2.1317\u001b[0m       \u001b[32m0.5978\u001b[0m        \u001b[35m2.1090\u001b[0m  2.5047\n",
      "      5        \u001b[36m2.0828\u001b[0m       \u001b[32m0.6556\u001b[0m        \u001b[35m2.0594\u001b[0m  2.4073\n",
      "      6        \u001b[36m2.0323\u001b[0m       \u001b[32m0.6887\u001b[0m        \u001b[35m2.0082\u001b[0m  2.4480\n",
      "      7        \u001b[36m1.9801\u001b[0m       \u001b[32m0.7154\u001b[0m        \u001b[35m1.9551\u001b[0m  2.3055\n",
      "      8        \u001b[36m1.9259\u001b[0m       \u001b[32m0.7297\u001b[0m        \u001b[35m1.9001\u001b[0m  2.3026\n",
      "      9        \u001b[36m1.8700\u001b[0m       \u001b[32m0.7386\u001b[0m        \u001b[35m1.8434\u001b[0m  2.2509\n",
      "     10        \u001b[36m1.8125\u001b[0m       \u001b[32m0.7468\u001b[0m        \u001b[35m1.7852\u001b[0m  2.5275\n",
      "     11        \u001b[36m1.7536\u001b[0m       \u001b[32m0.7538\u001b[0m        \u001b[35m1.7260\u001b[0m  2.5215\n",
      "     12        \u001b[36m1.6940\u001b[0m       \u001b[32m0.7583\u001b[0m        \u001b[35m1.6662\u001b[0m  2.3278\n",
      "     13        \u001b[36m1.6341\u001b[0m       \u001b[32m0.7611\u001b[0m        \u001b[35m1.6064\u001b[0m  2.4427\n",
      "     14        \u001b[36m1.5744\u001b[0m       \u001b[32m0.7646\u001b[0m        \u001b[35m1.5472\u001b[0m  2.1982\n",
      "     15        \u001b[36m1.5156\u001b[0m       \u001b[32m0.7679\u001b[0m        \u001b[35m1.4890\u001b[0m  2.4702\n",
      "     16        \u001b[36m1.4580\u001b[0m       \u001b[32m0.7725\u001b[0m        \u001b[35m1.4325\u001b[0m  2.4937\n",
      "     17        \u001b[36m1.4022\u001b[0m       \u001b[32m0.7783\u001b[0m        \u001b[35m1.3778\u001b[0m  2.4542\n",
      "     18        \u001b[36m1.3486\u001b[0m       \u001b[32m0.7817\u001b[0m        \u001b[35m1.3255\u001b[0m  2.4034\n",
      "     19        \u001b[36m1.2973\u001b[0m       \u001b[32m0.7854\u001b[0m        \u001b[35m1.2756\u001b[0m  2.4352\n",
      "     20        \u001b[36m1.2486\u001b[0m       \u001b[32m0.7878\u001b[0m        \u001b[35m1.2284\u001b[0m  2.4301\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.2757\u001b[0m       \u001b[32m0.3225\u001b[0m        \u001b[35m2.2514\u001b[0m  2.1922\n",
      "      2        \u001b[36m2.2278\u001b[0m       \u001b[32m0.4752\u001b[0m        \u001b[35m2.2039\u001b[0m  2.4529\n",
      "      3        \u001b[36m2.1804\u001b[0m       \u001b[32m0.5929\u001b[0m        \u001b[35m2.1563\u001b[0m  2.5273\n",
      "      4        \u001b[36m2.1326\u001b[0m       \u001b[32m0.6446\u001b[0m        \u001b[35m2.1080\u001b[0m  2.5443\n",
      "      5        \u001b[36m2.0836\u001b[0m       \u001b[32m0.6756\u001b[0m        \u001b[35m2.0583\u001b[0m  2.6174\n",
      "      6        \u001b[36m2.0331\u001b[0m       \u001b[32m0.7013\u001b[0m        \u001b[35m2.0069\u001b[0m  2.7908\n",
      "      7        \u001b[36m1.9808\u001b[0m       \u001b[32m0.7163\u001b[0m        \u001b[35m1.9536\u001b[0m  2.7410\n",
      "      8        \u001b[36m1.9266\u001b[0m       \u001b[32m0.7283\u001b[0m        \u001b[35m1.8984\u001b[0m  2.5353\n",
      "      9        \u001b[36m1.8704\u001b[0m       \u001b[32m0.7368\u001b[0m        \u001b[35m1.8414\u001b[0m  2.3726\n",
      "     10        \u001b[36m1.8126\u001b[0m       \u001b[32m0.7438\u001b[0m        \u001b[35m1.7829\u001b[0m  2.3224\n",
      "     11        \u001b[36m1.7535\u001b[0m       \u001b[32m0.7498\u001b[0m        \u001b[35m1.7234\u001b[0m  2.5132\n",
      "     12        \u001b[36m1.6936\u001b[0m       \u001b[32m0.7571\u001b[0m        \u001b[35m1.6632\u001b[0m  2.2337\n",
      "     13        \u001b[36m1.6334\u001b[0m       \u001b[32m0.7637\u001b[0m        \u001b[35m1.6031\u001b[0m  2.1946\n",
      "     14        \u001b[36m1.5734\u001b[0m       \u001b[32m0.7703\u001b[0m        \u001b[35m1.5435\u001b[0m  2.4019\n",
      "     15        \u001b[36m1.5142\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m1.4850\u001b[0m  2.3732\n",
      "     16        \u001b[36m1.4564\u001b[0m       \u001b[32m0.7786\u001b[0m        \u001b[35m1.4280\u001b[0m  2.3151\n",
      "     17        \u001b[36m1.4003\u001b[0m       \u001b[32m0.7843\u001b[0m        \u001b[35m1.3731\u001b[0m  2.3679\n",
      "     18        \u001b[36m1.3465\u001b[0m       \u001b[32m0.7894\u001b[0m        \u001b[35m1.3205\u001b[0m  2.2314\n",
      "     19        \u001b[36m1.2950\u001b[0m       \u001b[32m0.7933\u001b[0m        \u001b[35m1.2705\u001b[0m  2.2224\n",
      "     20        \u001b[36m1.2462\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m1.2231\u001b[0m  2.3281\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.2806\u001b[0m       \u001b[32m0.1933\u001b[0m        \u001b[35m2.2669\u001b[0m  1.2866\n",
      "      2        \u001b[36m2.2523\u001b[0m       \u001b[32m0.2516\u001b[0m        \u001b[35m2.2375\u001b[0m  1.3099\n",
      "      3        \u001b[36m2.2223\u001b[0m       \u001b[32m0.2933\u001b[0m        \u001b[35m2.2067\u001b[0m  1.3608\n",
      "      4        \u001b[36m2.1911\u001b[0m       \u001b[32m0.3254\u001b[0m        \u001b[35m2.1750\u001b[0m  1.2650\n",
      "      5        \u001b[36m2.1591\u001b[0m       \u001b[32m0.3538\u001b[0m        \u001b[35m2.1425\u001b[0m  1.2435\n",
      "      6        \u001b[36m2.1262\u001b[0m       \u001b[32m0.3824\u001b[0m        \u001b[35m2.1090\u001b[0m  1.2125\n",
      "      7        \u001b[36m2.0921\u001b[0m       \u001b[32m0.4114\u001b[0m        \u001b[35m2.0741\u001b[0m  1.1941\n",
      "      8        \u001b[36m2.0566\u001b[0m       \u001b[32m0.4394\u001b[0m        \u001b[35m2.0378\u001b[0m  1.1787\n",
      "      9        \u001b[36m2.0196\u001b[0m       \u001b[32m0.4689\u001b[0m        \u001b[35m1.9997\u001b[0m  1.2464\n",
      "     10        \u001b[36m1.9802\u001b[0m       \u001b[32m0.5057\u001b[0m        \u001b[35m1.9584\u001b[0m  1.1937\n",
      "     11        \u001b[36m1.9373\u001b[0m       \u001b[32m0.5527\u001b[0m        \u001b[35m1.9142\u001b[0m  1.1749\n",
      "     12        \u001b[36m1.8927\u001b[0m       \u001b[32m0.5914\u001b[0m        \u001b[35m1.8692\u001b[0m  1.1935\n",
      "     13        \u001b[36m1.8475\u001b[0m       \u001b[32m0.6217\u001b[0m        \u001b[35m1.8236\u001b[0m  1.1829\n",
      "     14        \u001b[36m1.8017\u001b[0m       \u001b[32m0.6419\u001b[0m        \u001b[35m1.7775\u001b[0m  1.1974\n",
      "     15        \u001b[36m1.7554\u001b[0m       \u001b[32m0.6589\u001b[0m        \u001b[35m1.7309\u001b[0m  1.2433\n",
      "     16        \u001b[36m1.7088\u001b[0m       \u001b[32m0.6694\u001b[0m        \u001b[35m1.6842\u001b[0m  1.1752\n",
      "     17        \u001b[36m1.6620\u001b[0m       \u001b[32m0.6773\u001b[0m        \u001b[35m1.6375\u001b[0m  1.1878\n",
      "     18        \u001b[36m1.6153\u001b[0m       \u001b[32m0.6848\u001b[0m        \u001b[35m1.5910\u001b[0m  1.1814\n",
      "     19        \u001b[36m1.5689\u001b[0m       \u001b[32m0.6927\u001b[0m        \u001b[35m1.5449\u001b[0m  1.1887\n",
      "     20        \u001b[36m1.5230\u001b[0m       \u001b[32m0.6981\u001b[0m        \u001b[35m1.4994\u001b[0m  1.2395\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.2844\u001b[0m       \u001b[32m0.2205\u001b[0m        \u001b[35m2.2659\u001b[0m  1.1761\n",
      "      2        \u001b[36m2.2468\u001b[0m       \u001b[32m0.2900\u001b[0m        \u001b[35m2.2281\u001b[0m  1.1810\n",
      "      3        \u001b[36m2.2086\u001b[0m       \u001b[32m0.3524\u001b[0m        \u001b[35m2.1897\u001b[0m  1.1924\n",
      "      4        \u001b[36m2.1697\u001b[0m       \u001b[32m0.4189\u001b[0m        \u001b[35m2.1504\u001b[0m  1.1814\n",
      "      5        \u001b[36m2.1298\u001b[0m       \u001b[32m0.4746\u001b[0m        \u001b[35m2.1102\u001b[0m  1.2443\n",
      "      6        \u001b[36m2.0890\u001b[0m       \u001b[32m0.5176\u001b[0m        \u001b[35m2.0691\u001b[0m  1.1887\n",
      "      7        \u001b[36m2.0473\u001b[0m       \u001b[32m0.5476\u001b[0m        \u001b[35m2.0272\u001b[0m  1.1772\n",
      "      8        \u001b[36m2.0049\u001b[0m       \u001b[32m0.5686\u001b[0m        \u001b[35m1.9846\u001b[0m  1.1910\n",
      "      9        \u001b[36m1.9618\u001b[0m       \u001b[32m0.5829\u001b[0m        \u001b[35m1.9413\u001b[0m  1.1955\n",
      "     10        \u001b[36m1.9180\u001b[0m       \u001b[32m0.5971\u001b[0m        \u001b[35m1.8972\u001b[0m  1.2880\n",
      "     11        \u001b[36m1.8734\u001b[0m       \u001b[32m0.6148\u001b[0m        \u001b[35m1.8524\u001b[0m  1.2328\n",
      "     12        \u001b[36m1.8280\u001b[0m       \u001b[32m0.6303\u001b[0m        \u001b[35m1.8067\u001b[0m  1.2255\n",
      "     13        \u001b[36m1.7819\u001b[0m       \u001b[32m0.6463\u001b[0m        \u001b[35m1.7603\u001b[0m  1.2273\n",
      "     14        \u001b[36m1.7351\u001b[0m       \u001b[32m0.6625\u001b[0m        \u001b[35m1.7133\u001b[0m  1.2213\n",
      "     15        \u001b[36m1.6878\u001b[0m       \u001b[32m0.6760\u001b[0m        \u001b[35m1.6659\u001b[0m  1.2817\n",
      "     16        \u001b[36m1.6402\u001b[0m       \u001b[32m0.6843\u001b[0m        \u001b[35m1.6183\u001b[0m  1.2348\n",
      "     17        \u001b[36m1.5925\u001b[0m       \u001b[32m0.6924\u001b[0m        \u001b[35m1.5707\u001b[0m  1.2220\n",
      "     18        \u001b[36m1.5451\u001b[0m       \u001b[32m0.7016\u001b[0m        \u001b[35m1.5235\u001b[0m  1.2414\n",
      "     19        \u001b[36m1.4982\u001b[0m       \u001b[32m0.7079\u001b[0m        \u001b[35m1.4771\u001b[0m  1.2836\n",
      "     20        \u001b[36m1.4522\u001b[0m       \u001b[32m0.7167\u001b[0m        \u001b[35m1.4317\u001b[0m  1.2143\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.9921\u001b[0m       \u001b[32m0.7503\u001b[0m        \u001b[35m1.6485\u001b[0m  0.7688\n",
      "      2        \u001b[36m1.3190\u001b[0m       \u001b[32m0.8063\u001b[0m        \u001b[35m1.0448\u001b[0m  0.8012\n",
      "      3        \u001b[36m0.8814\u001b[0m       \u001b[32m0.8378\u001b[0m        \u001b[35m0.7606\u001b[0m  0.8094\n",
      "      4        \u001b[36m0.6815\u001b[0m       \u001b[32m0.8527\u001b[0m        \u001b[35m0.6252\u001b[0m  0.8247\n",
      "      5        \u001b[36m0.5781\u001b[0m       \u001b[32m0.8638\u001b[0m        \u001b[35m0.5488\u001b[0m  0.8494\n",
      "      6        \u001b[36m0.5156\u001b[0m       \u001b[32m0.8714\u001b[0m        \u001b[35m0.4999\u001b[0m  0.8382\n",
      "      7        \u001b[36m0.4738\u001b[0m       \u001b[32m0.8771\u001b[0m        \u001b[35m0.4660\u001b[0m  0.9346\n",
      "      8        \u001b[36m0.4438\u001b[0m       \u001b[32m0.8806\u001b[0m        \u001b[35m0.4411\u001b[0m  0.8691\n",
      "      9        \u001b[36m0.4211\u001b[0m       \u001b[32m0.8838\u001b[0m        \u001b[35m0.4220\u001b[0m  0.8792\n",
      "     10        \u001b[36m0.4031\u001b[0m       \u001b[32m0.8870\u001b[0m        \u001b[35m0.4067\u001b[0m  0.9071\n",
      "     11        \u001b[36m0.3885\u001b[0m       \u001b[32m0.8887\u001b[0m        \u001b[35m0.3942\u001b[0m  0.8791\n",
      "     12        \u001b[36m0.3762\u001b[0m       \u001b[32m0.8903\u001b[0m        \u001b[35m0.3837\u001b[0m  0.9522\n",
      "     13        \u001b[36m0.3657\u001b[0m       \u001b[32m0.8921\u001b[0m        \u001b[35m0.3747\u001b[0m  0.8848\n",
      "     14        \u001b[36m0.3565\u001b[0m       \u001b[32m0.8948\u001b[0m        \u001b[35m0.3669\u001b[0m  0.8922\n",
      "     15        \u001b[36m0.3484\u001b[0m       \u001b[32m0.8957\u001b[0m        \u001b[35m0.3599\u001b[0m  0.8808\n",
      "     16        \u001b[36m0.3411\u001b[0m       \u001b[32m0.8981\u001b[0m        \u001b[35m0.3537\u001b[0m  0.8867\n",
      "     17        \u001b[36m0.3345\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.3481\u001b[0m  0.9498\n",
      "     18        \u001b[36m0.3284\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m0.3429\u001b[0m  0.8964\n",
      "     19        \u001b[36m0.3228\u001b[0m       \u001b[32m0.9013\u001b[0m        \u001b[35m0.3382\u001b[0m  0.8817\n",
      "     20        \u001b[36m0.3176\u001b[0m       \u001b[32m0.9027\u001b[0m        \u001b[35m0.3338\u001b[0m  0.9127\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.9884\u001b[0m       \u001b[32m0.7589\u001b[0m        \u001b[35m1.6370\u001b[0m  0.8585\n",
      "      2        \u001b[36m1.3046\u001b[0m       \u001b[32m0.8084\u001b[0m        \u001b[35m1.0330\u001b[0m  0.9473\n",
      "      3        \u001b[36m0.8695\u001b[0m       \u001b[32m0.8356\u001b[0m        \u001b[35m0.7547\u001b[0m  0.8713\n",
      "      4        \u001b[36m0.6739\u001b[0m       \u001b[32m0.8492\u001b[0m        \u001b[35m0.6230\u001b[0m  0.8842\n",
      "      5        \u001b[36m0.5726\u001b[0m       \u001b[32m0.8608\u001b[0m        \u001b[35m0.5480\u001b[0m  0.8773\n",
      "      6        \u001b[36m0.5111\u001b[0m       \u001b[32m0.8710\u001b[0m        \u001b[35m0.4998\u001b[0m  0.8783\n",
      "      7        \u001b[36m0.4696\u001b[0m       \u001b[32m0.8778\u001b[0m        \u001b[35m0.4662\u001b[0m  0.9490\n",
      "      8        \u001b[36m0.4397\u001b[0m       \u001b[32m0.8821\u001b[0m        \u001b[35m0.4413\u001b[0m  0.8877\n",
      "      9        \u001b[36m0.4169\u001b[0m       \u001b[32m0.8849\u001b[0m        \u001b[35m0.4222\u001b[0m  0.8854\n",
      "     10        \u001b[36m0.3989\u001b[0m       \u001b[32m0.8878\u001b[0m        \u001b[35m0.4069\u001b[0m  0.8778\n",
      "     11        \u001b[36m0.3843\u001b[0m       \u001b[32m0.8911\u001b[0m        \u001b[35m0.3943\u001b[0m  0.8853\n",
      "     12        \u001b[36m0.3720\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.3838\u001b[0m  0.9459\n",
      "     13        \u001b[36m0.3615\u001b[0m       \u001b[32m0.8956\u001b[0m        \u001b[35m0.3748\u001b[0m  0.8698\n",
      "     14        \u001b[36m0.3524\u001b[0m       \u001b[32m0.8970\u001b[0m        \u001b[35m0.3669\u001b[0m  0.8555\n",
      "     15        \u001b[36m0.3443\u001b[0m       \u001b[32m0.8984\u001b[0m        \u001b[35m0.3600\u001b[0m  0.8546\n",
      "     16        \u001b[36m0.3371\u001b[0m       \u001b[32m0.8998\u001b[0m        \u001b[35m0.3538\u001b[0m  0.8595\n",
      "     17        \u001b[36m0.3306\u001b[0m       \u001b[32m0.9019\u001b[0m        \u001b[35m0.3481\u001b[0m  0.8524\n",
      "     18        \u001b[36m0.3246\u001b[0m       \u001b[32m0.9021\u001b[0m        \u001b[35m0.3430\u001b[0m  0.9196\n",
      "     19        \u001b[36m0.3190\u001b[0m       \u001b[32m0.9040\u001b[0m        \u001b[35m0.3382\u001b[0m  0.8561\n",
      "     20        \u001b[36m0.3139\u001b[0m       \u001b[32m0.9056\u001b[0m        \u001b[35m0.3338\u001b[0m  0.8683\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.1380\u001b[0m       \u001b[32m0.6444\u001b[0m        \u001b[35m1.9021\u001b[0m  0.3537\n",
      "      2        \u001b[36m1.6048\u001b[0m       \u001b[32m0.7544\u001b[0m        \u001b[35m1.3136\u001b[0m  0.3651\n",
      "      3        \u001b[36m1.0997\u001b[0m       \u001b[32m0.8027\u001b[0m        \u001b[35m0.9298\u001b[0m  0.3550\n",
      "      4        \u001b[36m0.8172\u001b[0m       \u001b[32m0.8321\u001b[0m        \u001b[35m0.7304\u001b[0m  0.4082\n",
      "      5        \u001b[36m0.6648\u001b[0m       \u001b[32m0.8506\u001b[0m        \u001b[35m0.6181\u001b[0m  0.3515\n",
      "      6        \u001b[36m0.5750\u001b[0m       \u001b[32m0.8605\u001b[0m        \u001b[35m0.5494\u001b[0m  0.3477\n",
      "      7        \u001b[36m0.5178\u001b[0m       \u001b[32m0.8675\u001b[0m        \u001b[35m0.5043\u001b[0m  0.3557\n",
      "      8        \u001b[36m0.4789\u001b[0m       \u001b[32m0.8732\u001b[0m        \u001b[35m0.4728\u001b[0m  0.3431\n",
      "      9        \u001b[36m0.4508\u001b[0m       \u001b[32m0.8765\u001b[0m        \u001b[35m0.4496\u001b[0m  0.3469\n",
      "     10        \u001b[36m0.4296\u001b[0m       \u001b[32m0.8813\u001b[0m        \u001b[35m0.4319\u001b[0m  0.3348\n",
      "     11        \u001b[36m0.4129\u001b[0m       \u001b[32m0.8838\u001b[0m        \u001b[35m0.4178\u001b[0m  0.3439\n",
      "     12        \u001b[36m0.3994\u001b[0m       \u001b[32m0.8862\u001b[0m        \u001b[35m0.4064\u001b[0m  0.3928\n",
      "     13        \u001b[36m0.3882\u001b[0m       \u001b[32m0.8884\u001b[0m        \u001b[35m0.3969\u001b[0m  0.3318\n",
      "     14        \u001b[36m0.3786\u001b[0m       \u001b[32m0.8898\u001b[0m        \u001b[35m0.3888\u001b[0m  0.3277\n",
      "     15        \u001b[36m0.3704\u001b[0m       \u001b[32m0.8919\u001b[0m        \u001b[35m0.3818\u001b[0m  0.3352\n",
      "     16        \u001b[36m0.3631\u001b[0m       \u001b[32m0.8946\u001b[0m        \u001b[35m0.3757\u001b[0m  0.3316\n",
      "     17        \u001b[36m0.3566\u001b[0m       \u001b[32m0.8959\u001b[0m        \u001b[35m0.3703\u001b[0m  0.3261\n",
      "     18        \u001b[36m0.3508\u001b[0m       \u001b[32m0.8973\u001b[0m        \u001b[35m0.3655\u001b[0m  0.3299\n",
      "     19        \u001b[36m0.3455\u001b[0m       \u001b[32m0.8986\u001b[0m        \u001b[35m0.3611\u001b[0m  0.3341\n",
      "     20        \u001b[36m0.3407\u001b[0m       0.8983        \u001b[35m0.3571\u001b[0m  0.3358\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.1725\u001b[0m       \u001b[32m0.4848\u001b[0m        \u001b[35m1.9679\u001b[0m  0.3454\n",
      "      2        \u001b[36m1.6876\u001b[0m       \u001b[32m0.7294\u001b[0m        \u001b[35m1.3954\u001b[0m  0.3686\n",
      "      3        \u001b[36m1.1620\u001b[0m       \u001b[32m0.7868\u001b[0m        \u001b[35m0.9741\u001b[0m  0.4206\n",
      "      4        \u001b[36m0.8509\u001b[0m       \u001b[32m0.8252\u001b[0m        \u001b[35m0.7585\u001b[0m  0.3747\n",
      "      5        \u001b[36m0.6882\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.6407\u001b[0m  0.3849\n",
      "      6        \u001b[36m0.5942\u001b[0m       \u001b[32m0.8598\u001b[0m        \u001b[35m0.5688\u001b[0m  0.3476\n",
      "      7        \u001b[36m0.5342\u001b[0m       \u001b[32m0.8668\u001b[0m        \u001b[35m0.5212\u001b[0m  0.3696\n",
      "      8        \u001b[36m0.4928\u001b[0m       \u001b[32m0.8756\u001b[0m        \u001b[35m0.4875\u001b[0m  0.3280\n",
      "      9        \u001b[36m0.4625\u001b[0m       \u001b[32m0.8789\u001b[0m        \u001b[35m0.4624\u001b[0m  0.3650\n",
      "     10        \u001b[36m0.4395\u001b[0m       \u001b[32m0.8832\u001b[0m        \u001b[35m0.4430\u001b[0m  0.3393\n",
      "     11        \u001b[36m0.4213\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.4275\u001b[0m  0.3283\n",
      "     12        \u001b[36m0.4065\u001b[0m       \u001b[32m0.8894\u001b[0m        \u001b[35m0.4149\u001b[0m  0.3317\n",
      "     13        \u001b[36m0.3941\u001b[0m       \u001b[32m0.8924\u001b[0m        \u001b[35m0.4043\u001b[0m  0.3945\n",
      "     14        \u001b[36m0.3836\u001b[0m       \u001b[32m0.8941\u001b[0m        \u001b[35m0.3953\u001b[0m  0.3815\n",
      "     15        \u001b[36m0.3745\u001b[0m       \u001b[32m0.8962\u001b[0m        \u001b[35m0.3875\u001b[0m  0.3567\n",
      "     16        \u001b[36m0.3665\u001b[0m       \u001b[32m0.8968\u001b[0m        \u001b[35m0.3806\u001b[0m  0.3611\n",
      "     17        \u001b[36m0.3594\u001b[0m       \u001b[32m0.8976\u001b[0m        \u001b[35m0.3745\u001b[0m  0.3513\n",
      "     18        \u001b[36m0.3530\u001b[0m       \u001b[32m0.8989\u001b[0m        \u001b[35m0.3690\u001b[0m  0.3811\n",
      "     19        \u001b[36m0.3471\u001b[0m       \u001b[32m0.9010\u001b[0m        \u001b[35m0.3641\u001b[0m  0.3674\n",
      "     20        \u001b[36m0.3418\u001b[0m       \u001b[32m0.9025\u001b[0m        \u001b[35m0.3596\u001b[0m  0.3665\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.3051\u001b[0m       \u001b[32m0.1287\u001b[0m        \u001b[35m2.3022\u001b[0m  0.8088\n",
      "      2        \u001b[36m2.2992\u001b[0m       \u001b[32m0.1356\u001b[0m        \u001b[35m2.2963\u001b[0m  0.8516\n",
      "      3        \u001b[36m2.2933\u001b[0m       \u001b[32m0.1435\u001b[0m        \u001b[35m2.2905\u001b[0m  0.8390\n",
      "      4        \u001b[36m2.2875\u001b[0m       \u001b[32m0.1516\u001b[0m        \u001b[35m2.2847\u001b[0m  0.9488\n",
      "      5        \u001b[36m2.2817\u001b[0m       \u001b[32m0.1598\u001b[0m        \u001b[35m2.2789\u001b[0m  0.9500\n",
      "      6        \u001b[36m2.2760\u001b[0m       \u001b[32m0.1698\u001b[0m        \u001b[35m2.2732\u001b[0m  0.9754\n",
      "      7        \u001b[36m2.2702\u001b[0m       \u001b[32m0.1832\u001b[0m        \u001b[35m2.2675\u001b[0m  0.9968\n",
      "      8        \u001b[36m2.2645\u001b[0m       \u001b[32m0.1984\u001b[0m        \u001b[35m2.2618\u001b[0m  1.1124\n",
      "      9        \u001b[36m2.2588\u001b[0m       \u001b[32m0.2175\u001b[0m        \u001b[35m2.2561\u001b[0m  1.0300\n",
      "     10        \u001b[36m2.2531\u001b[0m       \u001b[32m0.2359\u001b[0m        \u001b[35m2.2504\u001b[0m  1.1141\n",
      "     11        \u001b[36m2.2474\u001b[0m       \u001b[32m0.2548\u001b[0m        \u001b[35m2.2447\u001b[0m  1.0655\n",
      "     12        \u001b[36m2.2417\u001b[0m       \u001b[32m0.2743\u001b[0m        \u001b[35m2.2390\u001b[0m  1.1057\n",
      "     13        \u001b[36m2.2360\u001b[0m       \u001b[32m0.2981\u001b[0m        \u001b[35m2.2334\u001b[0m  1.2021\n",
      "     14        \u001b[36m2.2304\u001b[0m       \u001b[32m0.3229\u001b[0m        \u001b[35m2.2277\u001b[0m  1.2313\n",
      "     15        \u001b[36m2.2247\u001b[0m       \u001b[32m0.3460\u001b[0m        \u001b[35m2.2220\u001b[0m  1.1087\n",
      "     16        \u001b[36m2.2190\u001b[0m       \u001b[32m0.3663\u001b[0m        \u001b[35m2.2164\u001b[0m  1.1035\n",
      "     17        \u001b[36m2.2134\u001b[0m       \u001b[32m0.3857\u001b[0m        \u001b[35m2.2107\u001b[0m  1.1930\n",
      "     18        \u001b[36m2.2077\u001b[0m       \u001b[32m0.4017\u001b[0m        \u001b[35m2.2051\u001b[0m  1.1203\n",
      "     19        \u001b[36m2.2020\u001b[0m       \u001b[32m0.4184\u001b[0m        \u001b[35m2.1994\u001b[0m  1.2105\n",
      "     20        \u001b[36m2.1964\u001b[0m       \u001b[32m0.4335\u001b[0m        \u001b[35m2.1937\u001b[0m  1.1910\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.2979\u001b[0m       \u001b[32m0.1232\u001b[0m        \u001b[35m2.2944\u001b[0m  1.5126\n",
      "      2        \u001b[36m2.2922\u001b[0m       \u001b[32m0.1348\u001b[0m        \u001b[35m2.2886\u001b[0m  1.2579\n",
      "      3        \u001b[36m2.2864\u001b[0m       \u001b[32m0.1465\u001b[0m        \u001b[35m2.2828\u001b[0m  1.0165\n",
      "      4        \u001b[36m2.2807\u001b[0m       \u001b[32m0.1606\u001b[0m        \u001b[35m2.2771\u001b[0m  1.0065\n",
      "      5        \u001b[36m2.2749\u001b[0m       \u001b[32m0.1821\u001b[0m        \u001b[35m2.2714\u001b[0m  1.0804\n",
      "      6        \u001b[36m2.2692\u001b[0m       \u001b[32m0.2052\u001b[0m        \u001b[35m2.2657\u001b[0m  1.0324\n",
      "      7        \u001b[36m2.2636\u001b[0m       \u001b[32m0.2330\u001b[0m        \u001b[35m2.2600\u001b[0m  1.0594\n",
      "      8        \u001b[36m2.2579\u001b[0m       \u001b[32m0.2663\u001b[0m        \u001b[35m2.2544\u001b[0m  1.0873\n",
      "      9        \u001b[36m2.2523\u001b[0m       \u001b[32m0.2975\u001b[0m        \u001b[35m2.2487\u001b[0m  1.0582\n",
      "     10        \u001b[36m2.2466\u001b[0m       \u001b[32m0.3359\u001b[0m        \u001b[35m2.2431\u001b[0m  1.0189\n",
      "     11        \u001b[36m2.2410\u001b[0m       \u001b[32m0.3676\u001b[0m        \u001b[35m2.2375\u001b[0m  1.0464\n",
      "     12        \u001b[36m2.2354\u001b[0m       \u001b[32m0.4000\u001b[0m        \u001b[35m2.2318\u001b[0m  0.9098\n",
      "     13        \u001b[36m2.2297\u001b[0m       \u001b[32m0.4254\u001b[0m        \u001b[35m2.2262\u001b[0m  0.8612\n",
      "     14        \u001b[36m2.2241\u001b[0m       \u001b[32m0.4519\u001b[0m        \u001b[35m2.2206\u001b[0m  0.9475\n",
      "     15        \u001b[36m2.2185\u001b[0m       \u001b[32m0.4754\u001b[0m        \u001b[35m2.2150\u001b[0m  0.8632\n",
      "     16        \u001b[36m2.2129\u001b[0m       \u001b[32m0.4951\u001b[0m        \u001b[35m2.2094\u001b[0m  0.8440\n",
      "     17        \u001b[36m2.2073\u001b[0m       \u001b[32m0.5103\u001b[0m        \u001b[35m2.2038\u001b[0m  0.9119\n",
      "     18        \u001b[36m2.2017\u001b[0m       \u001b[32m0.5246\u001b[0m        \u001b[35m2.1981\u001b[0m  0.8356\n",
      "     19        \u001b[36m2.1960\u001b[0m       \u001b[32m0.5405\u001b[0m        \u001b[35m2.1925\u001b[0m  0.8399\n",
      "     20        \u001b[36m2.1904\u001b[0m       \u001b[32m0.5532\u001b[0m        \u001b[35m2.1869\u001b[0m  0.9150\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.3059\u001b[0m       \u001b[32m0.0997\u001b[0m        \u001b[35m2.3050\u001b[0m  0.3476\n",
      "      2        \u001b[36m2.3033\u001b[0m       \u001b[32m0.0998\u001b[0m        \u001b[35m2.3024\u001b[0m  0.3375\n",
      "      3        \u001b[36m2.3007\u001b[0m       0.0998        \u001b[35m2.2998\u001b[0m  0.3855\n",
      "      4        \u001b[36m2.2981\u001b[0m       0.0997        \u001b[35m2.2972\u001b[0m  0.3472\n",
      "      5        \u001b[36m2.2955\u001b[0m       0.0997        \u001b[35m2.2946\u001b[0m  0.3378\n",
      "      6        \u001b[36m2.2928\u001b[0m       0.0997        \u001b[35m2.2919\u001b[0m  0.3353\n",
      "      7        \u001b[36m2.2901\u001b[0m       0.0997        \u001b[35m2.2892\u001b[0m  0.3729\n",
      "      8        \u001b[36m2.2874\u001b[0m       0.0997        \u001b[35m2.2865\u001b[0m  0.3281\n",
      "      9        \u001b[36m2.2847\u001b[0m       0.0997        \u001b[35m2.2837\u001b[0m  0.3292\n",
      "     10        \u001b[36m2.2818\u001b[0m       0.0995        \u001b[35m2.2809\u001b[0m  0.3264\n",
      "     11        \u001b[36m2.2790\u001b[0m       0.0995        \u001b[35m2.2780\u001b[0m  0.3665\n",
      "     12        \u001b[36m2.2760\u001b[0m       0.0995        \u001b[35m2.2750\u001b[0m  0.3183\n",
      "     13        \u001b[36m2.2730\u001b[0m       0.0995        \u001b[35m2.2720\u001b[0m  0.3188\n",
      "     14        \u001b[36m2.2700\u001b[0m       0.0995        \u001b[35m2.2689\u001b[0m  0.3174\n",
      "     15        \u001b[36m2.2668\u001b[0m       0.0995        \u001b[35m2.2658\u001b[0m  0.3531\n",
      "     16        \u001b[36m2.2637\u001b[0m       0.0995        \u001b[35m2.2626\u001b[0m  0.3177\n",
      "     17        \u001b[36m2.2605\u001b[0m       0.0995        \u001b[35m2.2593\u001b[0m  0.3261\n",
      "     18        \u001b[36m2.2572\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.2560\u001b[0m  0.3195\n",
      "     19        \u001b[36m2.2539\u001b[0m       \u001b[32m0.1011\u001b[0m        \u001b[35m2.2527\u001b[0m  0.3626\n",
      "     20        \u001b[36m2.2505\u001b[0m       \u001b[32m0.1032\u001b[0m        \u001b[35m2.2493\u001b[0m  0.3141\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.2932\u001b[0m       \u001b[32m0.1214\u001b[0m        \u001b[35m2.2914\u001b[0m  0.3004\n",
      "      2        \u001b[36m2.2898\u001b[0m       \u001b[32m0.1284\u001b[0m        \u001b[35m2.2880\u001b[0m  0.3073\n",
      "      3        \u001b[36m2.2865\u001b[0m       \u001b[32m0.1352\u001b[0m        \u001b[35m2.2847\u001b[0m  0.3474\n",
      "      4        \u001b[36m2.2831\u001b[0m       \u001b[32m0.1417\u001b[0m        \u001b[35m2.2813\u001b[0m  0.3512\n",
      "      5        \u001b[36m2.2797\u001b[0m       \u001b[32m0.1489\u001b[0m        \u001b[35m2.2780\u001b[0m  0.3143\n",
      "      6        \u001b[36m2.2764\u001b[0m       \u001b[32m0.1551\u001b[0m        \u001b[35m2.2746\u001b[0m  0.3731\n",
      "      7        \u001b[36m2.2730\u001b[0m       \u001b[32m0.1625\u001b[0m        \u001b[35m2.2712\u001b[0m  0.4341\n",
      "      8        \u001b[36m2.2696\u001b[0m       \u001b[32m0.1700\u001b[0m        \u001b[35m2.2678\u001b[0m  0.4015\n",
      "      9        \u001b[36m2.2661\u001b[0m       \u001b[32m0.1792\u001b[0m        \u001b[35m2.2643\u001b[0m  0.3543\n",
      "     10        \u001b[36m2.2626\u001b[0m       \u001b[32m0.1883\u001b[0m        \u001b[35m2.2609\u001b[0m  0.3458\n",
      "     11        \u001b[36m2.2591\u001b[0m       \u001b[32m0.1959\u001b[0m        \u001b[35m2.2574\u001b[0m  0.3877\n",
      "     12        \u001b[36m2.2556\u001b[0m       \u001b[32m0.2019\u001b[0m        \u001b[35m2.2538\u001b[0m  0.4965\n",
      "     13        \u001b[36m2.2520\u001b[0m       \u001b[32m0.2100\u001b[0m        \u001b[35m2.2503\u001b[0m  0.4473\n",
      "     14        \u001b[36m2.2484\u001b[0m       \u001b[32m0.2160\u001b[0m        \u001b[35m2.2467\u001b[0m  0.4031\n",
      "     15        \u001b[36m2.2448\u001b[0m       \u001b[32m0.2249\u001b[0m        \u001b[35m2.2430\u001b[0m  0.3974\n",
      "     16        \u001b[36m2.2411\u001b[0m       \u001b[32m0.2316\u001b[0m        \u001b[35m2.2394\u001b[0m  0.4162\n",
      "     17        \u001b[36m2.2374\u001b[0m       \u001b[32m0.2397\u001b[0m        \u001b[35m2.2357\u001b[0m  0.3721\n",
      "     18        \u001b[36m2.2337\u001b[0m       \u001b[32m0.2468\u001b[0m        \u001b[35m2.2319\u001b[0m  0.3965\n",
      "     19        \u001b[36m2.2299\u001b[0m       \u001b[32m0.2524\u001b[0m        \u001b[35m2.2281\u001b[0m  0.4324\n",
      "     20        \u001b[36m2.2261\u001b[0m       \u001b[32m0.2562\u001b[0m        \u001b[35m2.2243\u001b[0m  0.3627\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=NeuralNetClassifier(_params_to_validate=set(), batch_size=64, callbacks=None, compile=False, criterion=&lt;class &#x27;torch.nn.modules.loss.CrossEntropyLoss&#x27;&gt;, dataset=&lt;class &#x27;skorch.dataset.Dataset&#x27;&gt;, device=&#x27;cpu&#x27;, iterator_train=&lt;class &#x27;torch.utils.data.dataloader.DataLoader&#x27;&gt;, iterator_valid=&lt;class &#x27;torch.utils.data.dataloader.DataLoader&#x27;&gt;, lr=0.001, max_epochs=20, module=&lt;class &#x27;__main__.MyModel&#x27;&gt;, optimizer=&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;, predict_nonlinearity=&#x27;auto&#x27;, torch_load_kwargs=None, use_caching=&#x27;auto&#x27;, verbose=1, warm_start=False),\n",
       "             param_grid={&#x27;batch_size&#x27;: [16, 128], &#x27;lr&#x27;: [0.01, 0.0001],\n",
       "                         &#x27;module__k_intermediate_neurons&#x27;: [1000, 20]},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=NeuralNetClassifier(_params_to_validate=set(), batch_size=64, callbacks=None, compile=False, criterion=&lt;class &#x27;torch.nn.modules.loss.CrossEntropyLoss&#x27;&gt;, dataset=&lt;class &#x27;skorch.dataset.Dataset&#x27;&gt;, device=&#x27;cpu&#x27;, iterator_train=&lt;class &#x27;torch.utils.data.dataloader.DataLoader&#x27;&gt;, iterator_valid=&lt;class &#x27;torch.utils.data.dataloader.DataLoader&#x27;&gt;, lr=0.001, max_epochs=20, module=&lt;class &#x27;__main__.MyModel&#x27;&gt;, optimizer=&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;, predict_nonlinearity=&#x27;auto&#x27;, torch_load_kwargs=None, use_caching=&#x27;auto&#x27;, verbose=1, warm_start=False),\n",
       "             param_grid={&#x27;batch_size&#x27;: [16, 128], &#x27;lr&#x27;: [0.01, 0.0001],\n",
       "                         &#x27;module__k_intermediate_neurons&#x27;: [1000, 20]},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: NeuralNetClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.MyModel&#x27;&gt;,\n",
       ")</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>NeuralNetClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.MyModel&#x27;&gt;,\n",
       ")</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=NeuralNetClassifier(_params_to_validate=set(), batch_size=64, callbacks=None, compile=False, criterion=<class 'torch.nn.modules.loss.CrossEntropyLoss'>, dataset=<class 'skorch.dataset.Dataset'>, device='cpu', iterator_train=<class 'torch.utils.data.dataloader.DataLoader'>, iterator_valid=<class 'torch.utils.data.dataloader.DataLoader'>, lr=0.001, max_epochs=20, module=<class '__main__.MyModel'>, optimizer=<class 'torch.optim.sgd.SGD'>, predict_nonlinearity='auto', torch_load_kwargs=None, use_caching='auto', verbose=1, warm_start=False),\n",
       "             param_grid={'batch_size': [16, 128], 'lr': [0.01, 0.0001],\n",
       "                         'module__k_intermediate_neurons': [1000, 20]},\n",
       "             refit=False, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6 Part 2 : \n",
    "\n",
    "#Class MyModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, nbfeatures=784, k_intermediate_neurons=100):\n",
    "        self.k_intermediate_neurons = k_intermediate_neurons\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(nbfeatures, k_intermediate_neurons)\n",
    "        self.fc2 = nn.Linear(k_intermediate_neurons,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# on lit les données\n",
    "((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('mnist_TP1.pkl.gz'))\n",
    "\n",
    "#Hyperparamètres\n",
    "k_intermediate_neurons = [1000,500,100,20]\n",
    "batch_size = [16,32,64,128] # nombre de données lues à chaque fois\n",
    "eta = [0.01,0.0075,0.005,0.0025] # taux d'apprentissage\n",
    "\n",
    "# on crée les lecteurs de données\n",
    "net = NeuralNetClassifier(\n",
    "    MyModel,\n",
    "    max_epochs=20,\n",
    "    lr=0.001,\n",
    "    batch_size=64,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "X_trf = data_train.numpy()\n",
    "y_trf = torch.argmax(label_train, dim=1).numpy()\n",
    "\n",
    "#X_trf = train_dataset\n",
    "#y_trf = test_loader.reshape(-1, 1)\n",
    "print(X_trf.shape,y_trf.shape)\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01,0.0001],\n",
    "    'batch_size': [16,128],\n",
    "    'module__k_intermediate_neurons': [1000,20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, scoring='accuracy', verbose=1, cv=2)\n",
    "\n",
    "gs.fit(X_trf, y_trf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cbe7e5-422b-4225-842b-9b00752111bf",
   "metadata": {},
   "source": [
    "# 6 bis : GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9982c5dd-5159-469c-ab8a-910339bc7fd2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size comparison train / test / validation : torch.Size([56000, 784]) / torch.Size([7000, 784]) / torch.Size([7000, 784])\n",
      "tensor([0.9537])\n",
      "tensor([0.9650])\n",
      "tensor([0.9707])\n",
      "tensor([0.9737])\n",
      "tensor([0.9746])\n",
      "tensor([0.9731])\n",
      "tensor([0.9777])\n",
      "tensor([0.9769])\n",
      "tensor([0.9764])\n",
      "tensor([0.9791])\n",
      "tensor([0.9789])\n",
      "tensor([0.9811])\n",
      "tensor([0.9806])\n",
      "tensor([0.9801])\n",
      "tensor([0.9790])\n",
      "tensor([0.9800])\n",
      "tensor([0.9797])\n",
      "tensor([0.9799])\n",
      "tensor([0.9799])\n",
      "tensor([0.9797])\n",
      "tensor([0.9780])\n",
      "tensor([0.9810])\n",
      "tensor([0.9813])\n",
      "tensor([0.9807])\n",
      "tensor([0.9804])\n",
      "tensor([0.9799])\n",
      "tensor([0.9799])\n",
      "tensor([0.9813])\n",
      "tensor([0.9809])\n",
      "tensor([0.9801])\n",
      "Avec données de validation : tensor([0.9770])\n"
     ]
    }
   ],
   "source": [
    "# on lit les données\n",
    "((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('mnist_TP1.pkl.gz'))\n",
    "\n",
    "#Hyperparamètres\n",
    "k_intermediate_neurons = 500\n",
    "batch_size = 64 # nombre de données lues à chaque fois\n",
    "nb_epochs = 30 # nombre de fois que la base de données sera lue\n",
    "eta = 0.005 # taux d'apprentissage\n",
    "\n",
    "# on crée les lecteurs de données\n",
    "\n",
    "#on extrait des données de validation de data_train, pour avoir 7000/7000/56000 soit 10/10/80%\n",
    "data_validation = data_train[:7000]\n",
    "data_train = data_train[7000:]\n",
    "label_validation = label_train[:7000]\n",
    "label_train = label_train[7000:]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(data_train,label_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(data_test,label_test)\n",
    "validation_dataset = torch.utils.data.TensorDataset(data_validation,label_validation)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"size comparison train / test / validation : {data_train.shape} / {data_test.shape} / {data_validation.shape}\")\n",
    "\n",
    "# on initialise le modèle et ses poids\n",
    "model = MyModel(data_train.shape[1], k_intermediate_neurons)\n",
    "\n",
    "# on initiliase l'optimiseur\n",
    "loss_func = torch.nn.MSELoss(reduction='sum')\n",
    "optim = torch.optim.SGD(model.parameters(), lr=eta)\n",
    "\n",
    "for n in range(nb_epochs):\n",
    "    # on lit toutes les données d'apprentissage\n",
    "    for x,t in train_loader:\n",
    "        model.train()\n",
    "        optim.zero_grad()\n",
    "        # on calcule la sortie du modèle\n",
    "        y = model(x)\n",
    "        # on met à jour les poids\n",
    "        loss = loss_func(t,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    # test du modèle (on évalue la progression pendant l'apprentissage)\n",
    "    acc = 0\n",
    "    # on lit toutes les donnéees de test\n",
    "    for x,t in test_loader:\n",
    "        # on calcule la sortie du modèle\n",
    "        y = model(x)\n",
    "        # on regarde si la sortie est correcte\n",
    "        acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "    # on affiche le pourcentage de bonnes réponses\n",
    "    print(acc/data_test.shape[0])\n",
    "\n",
    "\n",
    "acc = 0\n",
    "for x,t in validation_loader :\n",
    "    # on calcule la sortie du modèle\n",
    "    y = model(x)\n",
    "    # on regarde si la sortie est correcte\n",
    "    acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "# on affiche le pourcentage de bonnes réponses\n",
    "print(f\"Avec données de validation : {acc/data_validation.shape[0]}\")\n",
    "\n",
    "# Comment nous avons optimisé les Hyper-paramètres : \n",
    "# Sans puissance de calcul, nous avons fait ça manuellement jusqu'à obtenir des résultats satisfaisants. \n",
    "#1 - Nous avons augmenté le learning rate jusqu'à voir l'overfitting apparaître en 10 epochs\n",
    "#2 - Taille du batch : choix d'une taille donant de bonnes performances et de bons résultats\n",
    "#3 - Taille de la couche intermédiare : essai de 5 valeurs, choix de la meilleure option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a93c78d-80b7-43ce-819d-b31e87303be7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9770])\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for x,t in validation_loader :\n",
    "    # on calcule la sortie du modèle\n",
    "    y = model(x)\n",
    "    # on regarde si la sortie est correcte\n",
    "    acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "# on affiche le pourcentage de bonnes réponses\n",
    "print(acc/data_validation.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c0c89-fe08-45b4-b187-9cd9934a7a52",
   "metadata": {},
   "source": [
    "# 7  Part 3 : Deep network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29091515-435b-419b-a996-fc071fc1ecf5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n : 0 acc : tensor([0.8380])\n",
      "epoch n : 1 acc : tensor([0.9141])\n",
      "epoch n : 2 acc : tensor([0.9359])\n",
      "epoch n : 3 acc : tensor([0.9509])\n",
      "epoch n : 4 acc : tensor([0.9596])\n",
      "epoch n : 5 acc : tensor([0.9650])\n",
      "epoch n : 6 acc : tensor([0.9630])\n",
      "tensor([0.9650])\n",
      "Arrêt au step 6 pour modèle 500 / 250 / 50\n",
      "epoch n : 0 acc : tensor([0.8860])\n",
      "epoch n : 1 acc : tensor([0.9179])\n",
      "epoch n : 2 acc : tensor([0.9281])\n",
      "epoch n : 3 acc : tensor([0.9419])\n",
      "epoch n : 4 acc : tensor([0.9474])\n",
      "epoch n : 5 acc : tensor([0.9553])\n",
      "epoch n : 6 acc : tensor([0.9596])\n",
      "epoch n : 7 acc : tensor([0.9650])\n",
      "epoch n : 8 acc : tensor([0.9661])\n",
      "epoch n : 9 acc : tensor([0.9699])\n",
      "epoch n : 10 acc : tensor([0.9690])\n",
      "tensor([0.9699])\n",
      "Arrêt au step 10 pour modèle 50 / 250 / 500\n",
      "epoch n : 0 acc : tensor([0.8441])\n",
      "epoch n : 1 acc : tensor([0.9129])\n",
      "epoch n : 2 acc : tensor([0.9316])\n",
      "epoch n : 3 acc : tensor([0.9463])\n",
      "epoch n : 4 acc : tensor([0.9554])\n",
      "epoch n : 5 acc : tensor([0.9586])\n",
      "epoch n : 6 acc : tensor([0.9643])\n",
      "epoch n : 7 acc : tensor([0.9681])\n",
      "epoch n : 8 acc : tensor([0.9670])\n",
      "tensor([0.9681])\n",
      "Arrêt au step 8 pour modèle 250 / 250 / 250\n",
      "epoch n : 0 acc : tensor([0.8443])\n",
      "epoch n : 1 acc : tensor([0.9139])\n",
      "epoch n : 2 acc : tensor([0.9390])\n",
      "epoch n : 3 acc : tensor([0.9500])\n",
      "epoch n : 4 acc : tensor([0.9593])\n",
      "epoch n : 5 acc : tensor([0.9631])\n",
      "epoch n : 6 acc : tensor([0.9661])\n",
      "epoch n : 7 acc : tensor([0.9711])\n",
      "epoch n : 8 acc : tensor([0.9746])\n",
      "epoch n : 9 acc : tensor([0.9744])\n",
      "tensor([0.9746])\n",
      "Arrêt au step 9 pour modèle 500 / 250 / 50\n",
      "epoch n : 0 acc : tensor([0.8753])\n",
      "epoch n : 1 acc : tensor([0.9151])\n",
      "epoch n : 2 acc : tensor([0.9347])\n",
      "epoch n : 3 acc : tensor([0.9470])\n",
      "epoch n : 4 acc : tensor([0.9539])\n",
      "epoch n : 5 acc : tensor([0.9546])\n",
      "epoch n : 6 acc : tensor([0.9614])\n",
      "epoch n : 7 acc : tensor([0.9607])\n",
      "tensor([0.9614])\n",
      "Arrêt au step 7 pour modèle 50 / 250 / 500\n",
      "epoch n : 0 acc : tensor([0.8594])\n",
      "epoch n : 1 acc : tensor([0.9084])\n",
      "epoch n : 2 acc : tensor([0.9314])\n",
      "epoch n : 3 acc : tensor([0.9453])\n",
      "epoch n : 4 acc : tensor([0.9531])\n",
      "epoch n : 5 acc : tensor([0.9596])\n",
      "epoch n : 6 acc : tensor([0.9626])\n",
      "epoch n : 7 acc : tensor([0.9694])\n",
      "epoch n : 8 acc : tensor([0.9709])\n",
      "epoch n : 9 acc : tensor([0.9743])\n",
      "epoch n : 10 acc : tensor([0.9736])\n",
      "tensor([0.9743])\n",
      "Arrêt au step 10 pour modèle 250 / 250 / 250\n"
     ]
    }
   ],
   "source": [
    "import gzip,numpy,torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ShallowNet(nn.Module):\n",
    "    def __init__(self, size_train, size_label, a, b, c):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(size_train, a)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(a, b)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.layer3 = torch.nn.Linear(b, c)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.layer4 = torch.nn.Linear(c, size_label)\n",
    "        self.sm = torch.nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.layer1(x)\n",
    "        res = self.relu1(res)\n",
    "        res = self.layer2(res)\n",
    "        res = self.relu2(res)\n",
    "        res = self.layer3(res)\n",
    "        res = self.relu3(res)\n",
    "        res = self.layer4(res)\n",
    "        res = self.sm(res)\n",
    "        return res\n",
    "\n",
    "\n",
    "def train_perso(a, b, c) :\n",
    "\n",
    "    #Hyperparamètres\n",
    "    batch_size = 64 # nombre de données lues à chaque fois\n",
    "    nb_epochs = 30 # nombre de fois que la base de données sera lue\n",
    "    eta = 0.001 # taux d'apprentissage\n",
    "    hidden_size = 500\n",
    "    \n",
    "    # on lit les données\n",
    "    ((data_train,label_train),(data_test,label_test)) = torch.load(gzip.open('mnist_TP1.pkl.gz'))\n",
    "    # on crée les lecteurs de données\n",
    "    train_dataset = torch.utils.data.TensorDataset(data_train,label_train)\n",
    "    test_dataset = torch.utils.data.TensorDataset(data_test,label_test)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    \n",
    "    model = ShallowNet(data_train.shape[1],label_train.shape[1], a, b, c)\n",
    "    \n",
    "    \n",
    "    # on initiliase l'optimiseur\n",
    "    loss_func = torch.nn.MSELoss(reduction='sum')\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=eta)\n",
    "\n",
    "    \n",
    "    acc = 0\n",
    "    for n in range(nb_epochs):\n",
    "        # on lit toutes les données d'apprentissage\n",
    "        for x,t in train_loader:\n",
    "            # on calcule la sortie du modèle\n",
    "            y = model(x)\n",
    "            # on met à jour les poids\n",
    "            loss = loss_func(t,y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "\n",
    "        # test du modèle (on évalue la progression pendant l'apprentissage)\n",
    "        acc_prec = acc\n",
    "        acc = float(0)\n",
    "        \n",
    "        # on lit toutes les donnéees de test\n",
    "        for x,t in test_loader:\n",
    "            # on calcule la sortie du modèle\n",
    "            y = model(x)\n",
    "            # on regarde si la sortie est correcte\n",
    "            acc += torch.argmax(y,1) == torch.argmax(t,1)\n",
    "\n",
    "        print(f\"epoch n : {n} acc : {acc/data_test.shape[0]}\")\n",
    "\n",
    "        #Arrêt prématuré si Overfitting\n",
    "        if acc < acc_prec :\n",
    "            \n",
    "            print(acc_prec/data_test.shape[0])\n",
    "            print(f\"Arrêt au step {n} pour modèle {a} / {b} / {c}\")\n",
    "            break\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "train_perso(500,250,50)\n",
    "train_perso(50,250,500)\n",
    "train_perso(250,250,250)\n",
    "train_perso(500,250,50)\n",
    "train_perso(50,250,500)\n",
    "train_perso(250,250,250)\n",
    "\n",
    "# Conclusion : la taille des couches n'importe peu, car les données sont \"simples\" et qu'un petit réseau à 1 couche suffit. \n",
    "# Le jeu sur les hyperparamètres permettant de s'entraîner plus a plus d'impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48fd47d-601d-4390-acef-44b2a81ec8f7",
   "metadata": {},
   "source": [
    "# 8 Part 4 : CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d14795-1b80-49ee-9072-4c8c8d7975db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Accuracy: 0.3598571428571429\n",
      "Epoch 2/30, Accuracy: 0.7684285714285715\n",
      "Epoch 3/30, Accuracy: 0.8694285714285714\n",
      "Epoch 4/30, Accuracy: 0.913\n",
      "Epoch 5/30, Accuracy: 0.9215714285714286\n",
      "Epoch 6/30, Accuracy: 0.944\n",
      "Epoch 7/30, Accuracy: 0.9488571428571428\n",
      "Epoch 8/30, Accuracy: 0.9601428571428572\n",
      "Epoch 9/30, Accuracy: 0.9557142857142857\n",
      "Epoch 10/30, Accuracy: 0.9575714285714285\n",
      "Epoch 11/30, Accuracy: 0.9722857142857143\n",
      "Epoch 12/30, Accuracy: 0.9734285714285714\n",
      "Epoch 13/30, Accuracy: 0.9734285714285714\n",
      "Epoch 14/30, Accuracy: 0.9764285714285714\n",
      "Epoch 15/30, Accuracy: 0.9764285714285714\n",
      "Epoch 16/30, Accuracy: 0.9748571428571429\n",
      "Epoch 17/30, Accuracy: 0.979\n",
      "Epoch 18/30, Accuracy: 0.977\n",
      "Epoch 19/30, Accuracy: 0.9767142857142858\n",
      "Epoch 20/30, Accuracy: 0.9782857142857143\n",
      "Epoch 21/30, Accuracy: 0.9794285714285714\n",
      "Epoch 22/30, Accuracy: 0.9801428571428571\n",
      "Epoch 23/30, Accuracy: 0.9761428571428571\n",
      "Epoch 24/30, Accuracy: 0.9802857142857143\n",
      "Epoch 25/30, Accuracy: 0.9817142857142858\n",
      "Epoch 26/30, Accuracy: 0.9817142857142858\n",
      "Epoch 27/30, Accuracy: 0.982\n",
      "Epoch 28/30, Accuracy: 0.9818571428571429\n",
      "Epoch 29/30, Accuracy: 0.9818571428571429\n",
      "Epoch 30/30, Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.relu1 = torch.nn.ReLU() #size : 24 * 24 * 6 \n",
    "        self.layer2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu2 = torch.nn.ReLU() #size : 12 * 12 * 6\n",
    "        self.layer3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu3 = torch.nn.ReLU() #size : 8 * 8 * 16\n",
    "        self.layer4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu4 = torch.nn.ReLU() #size : 4 * 4 * 16\n",
    "\n",
    "        # C5: Fully connected (Linear layer) (input: 16 * 4 * 4, output: 120)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "\n",
    "        # F6: Fully connected (Linear layer) (input: 120, output: 84)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "\n",
    "        # Output layer (Fully connected, input: 84, output: 10)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #On dé-flatten les données de base\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "\n",
    "        # Convolution + ReLU layers\n",
    "        res = self.layer1(x)\n",
    "        res = self.relu1(res)\n",
    "        res = self.layer2(res)\n",
    "        res = self.relu2(res)\n",
    "        res = self.layer3(res)\n",
    "        res = self.relu3(res)\n",
    "        res = self.layer4(res)\n",
    "        res = self.relu4(res)\n",
    "        \n",
    "        # Flatten the output of the convolution layers\n",
    "        res = res.view(res.size(0), -1)  # Reshape to (batch_size, 16 * 4 * 4)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        res = self.fc1(res)\n",
    "        res = F.relu(res)\n",
    "        res = self.fc2(res)\n",
    "        res = F.relu(res)\n",
    "        res = self.fc3(res)  # Output layer\n",
    "        return res\n",
    "\n",
    "t# Hyperparameters\n",
    "batch_size = 64  # number of data points per batch\n",
    "nb_epochs = 30   # number of times to iterate over the dataset\n",
    "eta = 0.005      # learning rate\n",
    "\n",
    "# Load data\n",
    "((data_train, label_train), (data_test, label_test)) = torch.load(gzip.open('mnist_TP1.pkl.gz'))\n",
    "\n",
    "label_train = torch.argmax(label_train, dim=1)\n",
    "label_test = torch.argmax(label_test, dim=1)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = torch.utils.data.TensorDataset(data_train, label_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(data_test, label_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = CNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_func = torch.nn.CrossEntropyLoss()  # Change MSELoss to CrossEntropyLoss for classification\n",
    "optim = torch.optim.SGD(model.parameters(), lr=eta)\n",
    "\n",
    "# Training loop\n",
    "for n in range(nb_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for x, t in train_loader:\n",
    "        optim.zero_grad()  # Clear gradients\n",
    "        y = model(x)       # Forward pass\n",
    "        loss = loss_func(y, t)  # Compute loss\n",
    "        loss.backward()    # Backward pass\n",
    "        optim.step()       # Update weights\n",
    "\n",
    "    # Test loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    acc = 0\n",
    "    with torch.no_grad():  # No need to compute gradients during testing\n",
    "        for x, t in test_loader:\n",
    "            y = model(x)\n",
    "            acc += (torch.argmax(y, 1) == t).item()\n",
    "    print(f'Epoch {n+1}/{nb_epochs}, Accuracy: {acc / len(data_test)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf277505-0a84-4b24-9c8c-d103c299a5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
